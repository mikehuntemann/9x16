## Doing "9x16"

If I had to put the whole process of "9x16" and the previous "Move to the Ocean" into one question, it would probably be something like this:
How to do research in a dynamic, fast pace, complex, limitless, "multi-media" environment?
And this under the premiss of and in anticipation with:
If you can not predict the future and don't know what you are going to learn, how can my process be open to any kind of output or "product"?

> "Good architectures allow major architectural decisions to be deferred. The job of an architect is not to make decisions, (...) it is to defer decision as long as possible to allow the program to be build in the absence of decisions, so that the decisions can be made later, with the most possible information." – [Uncle Bob Martin ("The Principles of Clean Architecture")](https://youtu.be/o_TH-Y78tt4?t=3993)

"9x16" is about the "know-how", explored in a mostly undirected research.
This work itself is a process, a series of experiments and case-studies, an expedition and a search for our current technological context and its histories.
It is a documentation and reflection of my personal experience how I work with – and sometime against – the Internet, social networks and platforms.

\newpage

### Messy Process, Well Documented

Cambridge Analytica,  
Facebook,  
list of sources,  
how to research,  
researching research tools,  
building research tools,  
screen research,  
desktop documentary,  
verticality,  
paradigm shifts,  
more sources,  
more screen recordings,  
more screenshots,  
Notion app,  
post-its,  
timeline,  
networks,  
relational databases,  
Mark Lombardi,  
cards and threads,  
atomizing content,  
building sequences,  
installation test,  
analog maps,  
digital archives,  
exchange formats,  
reference systems,  
the hosting problem.

\newpage


### Init / Derivée / Log

This all started with a "Daily Log" of what I am actually doing every day. I wanted to expose myself to my own habits and what I "subconsciously" spend time with. I wanted to become self-aware of my process. I did it for 30 days which was then interrupted by the "Cambridge Analytica scandal", which happened around in March 2018, and I started documenting my viewing habits, while the news were unfolding. So the question then became how I would search for information and for that I also started creating primitive watchlists in my Markdown editor "Ulysses".

When I first tried to define my project under code name "Move to the Ocean" I wrote the following on March 24, 2018:

> Thesis in fragments  
File format structuring  
Browser / application, online / offline usage  
„I can’t read whole texts anymore“  
Why are you writing texts then?  
Bias towards linear / storytelling  
Referencing vs creating  
Lightness of being: curating, thought process, dynamic vs linear  
Video grid, video referencing network  
Science as referencing network on the meta level  

How to „write“ documents? How to „document“ the process? How to archive what happens in the browser or apps? How to create a "database" or network of (personal) knowledge? How to manage the "evidence"?

In April 2018, I made an early proof-of-concept Twitter experiment and deconstructed articles into tweet-sized blocks. And it actually worked pretty well, but there were obviously a lot of constrains because it is not meant to be a "offline-first" personal knowledge and research management and writing tool.

Shortly after, I started to work on a series of projects about habits (and the self-documentation of them in the form of YouTube videos) related to mobile devices and social networks called "Early Birds". This also resulted in the deconstruction of YouTube specific genres and gathering data for a knowledge graph. In parallel, I was doing research and developing strategies on user interfaces and user experiences in another project.

This was a necessary experience for me personally, to look at software from a wholistic perspective, in two directions: the way software is designed for specific use-cases and how the users are actually using the software and what their expectations of functionalities and feedbacks are.

The semester ended with a workshop on research, which was interesting to see that almost everyone was overwhelmed with the amount of information and that the process itself tends to be very messy and unpredictable.

In the same breath, my professors told me to "plan" and "outline" my graduation project. And I couldn't do it. But I started documenting again.

In August 2018, I started the [“xResearch”](https://web.archive.org/web/20191120184646/http://blog.mikehuntemann.de/) blog on my website, summarizing my daily research interests and thoughts on my practice and approaches. It is mostly about the complexity problem, information overload and how I try to handle it personally. I quit writing “publicly” after two weeks.

Throughout the next 6 weeks, I tracked every topic, every video, that would cross my screen, what I was intuitively "drifting" towards.
I compressed them into the major themes and topics as well as into “personal”, "technical", "methodical" and “institutional” categories. The bottomline is: I am somehow obsessed with databases, knowledge management, archiving and documenting.

This was also overwhelming in itself, so I read "The Craft of Research" (19.09.2018) and looked for methods in the field of academic research and learn about their approaches. I closed the book after the sentence "Don't use the internet for your research." Error 404, Answers Not Found. One could argue that academic research doesn't like internet references or any references that are not "stable". This is interesting.

> I am studying the methods and processes of data collection and management because I want to find out if there are basic underlying principles in order to help other researchers to handle digital complexity with a set of tools.

This was somehow my mission statement, but quickly came back to some of my initial thoughts and questions:

> What if there were no documents anymore, just fragments?
How would research work when behaving more like email for quick incoming chunks? Rearranging, evolving.

This was also the time, somewhere around mid of October, that I would take my content from the temporary Wordpress blog and converting every entry to a Markdown file and putting it into single, self-reliant files locally on my computer and synced it to a Github repository. There was no need for a database and a backend anymore. I used Tower to push my new commits to keep the history of each file over time. For writing I used [Atom](https://atom.io/), an open source, extendable code editor developed by Github.
This way I could see the rendered Markdown file with a default styling and see all the changes made between the different commits.
I stopped shortly after but came back to it for the document you are reading right now.

The main problem was and still is interoperability and the loss of consistent references and information within the research process.
Basically, all my notes were now made in the default "Notes" app, just for convenience and mobile syncing reasons. And it "worked", for a while at least.

The new semester introduced me to the works of Kevin B. Lee, his video essays and visual approaches how to analyze and dissect visual content within video formats. I loved his work, but in hindsight it gave me the notion, that "my solution" should not be "text-based" because I am a "visual" researcher, studying "visual" communications. That is probably the biggest misconception throughout my studies, and gave me always misleading signals what my "job" as a student within the new media department should be. But more to that also later!

This input reminded me of how I used an automated browser for a performance in my ["#AlgorithmicWarfare"](https://web.archive.org/web/20181021224250/https://newmediakassel.com/mike-huntemann-algorithmic-warfare) (2017) project and I looked for possibilities, how to build a multi-window browser performance, to write "recipes" for an automated internet content collage.
In my research, I found some of the early Google Chrome experiments, that would demonstrate, how "film-making" in browser tabs could look like and how capable browser technology is with HTML5. The project is called ["The Wilderness Downtown"](https://web.archive.org/web/20100914191200/www.chromeexperiments.com/arcadefire) (2010). But my context specific problem with that was, that I would have to use content on mobile platforms, that could not be represented in the browser windows, so I dropped the idea.  

Strangely, or maybe out of pure necessity, I then got partly analog in March 2019. Writing and referencing interesting snippets of information and quotes from books, creating an overview of what I could permanently look at.

In this way, I documented everything in "little blocks" of assets in form of knowledge and references on post-its. The interfaces of the applications were just not good enough for this messy, personal, organic process with a lot of fragmented information!

![Gathering Material in "Building Blocks"](/Users/xr/Documents/VERTICAL/Vertical-One/assets/postit-wall.png)


Then I found the [Notion](https://www.notion.so/) app in April 2019, which was great and "block-based". So I converted all my notes into the applications database, were I would now be able to create structured databases for different kinds of topics. It is a pretty neat management tool, but I didn't really stick over the complete process of writing, "Notes" was always faster and leaner, more focused, easier to dump thoughts into it.
But "Notion" would stay as a management tool for catalogs of digital and analog resources and as a directory where I took the notes to each source. In addition to that, the "block system" is not interoperable with my "filesystem tools" because "Notion" works as a cloud platform and internalizes its own application specific file management. But that is also the reason, why it is for "normal use-cases" good enough.

![Timeline Segments for Timing and Context](/Users/xr/Documents/VERTICAL/Vertical-One/assets/notion-timeline.png)

But besides all of that, there was another problem: I couldn't reference the visuals, not with Notion and especially not with my post-its.

So I build a prototype with KirbyCMS in May 2019 – right after we had a workshop about it. Kirby only uses the filesystem for the backend of websites instead of databases like Wordpress.
From there I could manage, categorize and prepare my video snippets in the interface of Kirby, which would then add the files in the specific directory. This way I could also see, which videos or snippets I still need to download, and got immediate feedback and an overview what tasks were still open. It was also good for adding further meta data for each video or snippet and generating download commands for specific sections.

![KirbyCMS Video Asset Management on Local Filesystem](/Users/xr/Documents/VERTICAL/Vertical-One/assets/kirby-board.png)


So Kirby was now for indexing my video-based, reference preserving research content, but this tool is not meant to be the tool for the actual performance. And this is what brought me back to the possibility of doing a desktop documentary.
